# When your data is comprised of attributes with varying scales, many machine learning 
# algorithms can benefit from rescaling the attributes to all have the same scale. Often 
# this is referred to as normalization and attributes are often rescaled into the range 
# between 0 and 1. This is useful for optimization algorithms in used in the core of 
# machine learning algorithms like gradient descent. It is also useful for algorithms 
# that weight inputs like regression and neural networks and algorithms that use 
# distance measures like K-Nearest Neighbors. 

# Rescale data (between 0 and 1)
import pandas
import scipy
import numpy
from sklearn.preprocessing import MinMaxScaler
url = "https://goo.gl/vhm1eU"
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] 
dataframe = pandas.read_csv(url, names=names)
array = dataframe.values

# separate array into input and output components
X = array[:,0:8]
Y = array[:,8]
scaler = MinMaxScaler(feature_range=(0, 1))
rescaledX = scaler.fit_transform(X)

# summarize transformed data
numpy.set_printoptions(precision=3)
print(rescaledX[0:5,:])
